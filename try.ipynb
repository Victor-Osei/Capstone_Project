{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_25084\\911080447.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186850 entries, 0 to 186849\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Order_ID          186850 non-null  object        \n",
      " 1   Product           186305 non-null  object        \n",
      " 2   Quantity_Ordered  185950 non-null  float64       \n",
      " 3   Price_Each        185950 non-null  float64       \n",
      " 4   Order_Date        185950 non-null  datetime64[ns]\n",
      " 5   Purchase_Address  186305 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(3)\n",
      "memory usage: 8.6+ MB\n",
      "None\n",
      "  Order_ID                     Product  Quantity_Ordered  Price_Each  \\\n",
      "0   176558        USB-C Charging Cable               2.0       11.95   \n",
      "1      nan                         NaN               NaN         NaN   \n",
      "2   176559  Bose SoundSport Headphones               1.0       99.99   \n",
      "3   176560                Google Phone               1.0      600.00   \n",
      "4   176560            Wired Headphones               1.0       11.99   \n",
      "\n",
      "           Order_Date                      Purchase_Address  \n",
      "0 2019-04-19 08:46:00          917 1st St, Dallas, TX 75001  \n",
      "1                 NaT                                   NaN  \n",
      "2 2019-04-07 22:30:00     682 Chestnut St, Boston, MA 02215  \n",
      "3 2019-04-12 14:38:00  669 Spruce St, Los Angeles, CA 90001  \n",
      "4 2019-04-12 14:38:00  669 Spruce St, Los Angeles, CA 90001  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Define a function to clean each dataset\n",
    "def clean_dataset(df):\n",
    "    # Rename columns to a consistent format\n",
    "    df.rename(columns={\n",
    "        'Order ID': 'Order_ID',\n",
    "        'Quantity Ordered': 'Quantity_Ordered',\n",
    "        'Price Each': 'Price_Each',\n",
    "        'Order Date': 'Order_Date',\n",
    "        'Purchase Address': 'Purchase_Address'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Convert columns to the correct data types\n",
    "    df['Order_ID'] = df['Order_ID'].astype(str)\n",
    "    df['Quantity_Ordered'] = pd.to_numeric(df['Quantity_Ordered'], errors='coerce')\n",
    "    df['Price_Each'] = pd.to_numeric(df['Price_Each'], errors='coerce')\n",
    "    df['Order_Date'] = pd.to_datetime(df['Order_Date'], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming all files are stored in a folder\n",
    "file_paths = glob.glob('data/*.csv')\n",
    "\n",
    "# Read and clean each dataset, then concatenate them\n",
    "all_data = pd.concat([clean_dataset(pd.read_csv(file)) for file in file_paths], ignore_index=True)\n",
    "\n",
    "# Save the concatenated data to a new CSV file (optional)\n",
    "all_data.to_csv('cleaned_data.csv', index=False)\n",
    "\n",
    "# Check the resulting dataframe\n",
    "print(all_data.info())\n",
    "print(all_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Insights:\n",
    "\n",
    "The sales pattern is dominated by low-cost, frequently purchased items, with most customers buying small quantities per transaction.\n",
    "Premium products have lower sales volumes, indicating that customers are more price-sensitive and tend to purchase lower-priced items more frequently.\n",
    "Understanding this customer behavior can help in targeting promotions and inventory planning, focusing on high-turnover products while strategically positioning higher-priced items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the box plots provided for \"Price Each\" and \"Quantity Ordered,\" here are some key insights and observations:\n",
    "\n",
    "1. Price Each (Image 1):\n",
    "   - The median price (represented by the line in the box) is relatively low, likely around $50-100.\n",
    "   - There's a wide range of prices, with the box (representing the interquartile range) extending to about $200.\n",
    "   - There are many outliers above the upper whisker, indicated by individual points.\n",
    "   - Some extreme outliers exist at prices around $750, $1000, and $1750.\n",
    "   - The distribution is heavily right-skewed, with most items priced low but a few very expensive items.\n",
    "\n",
    "2. Quantity Ordered (Image 2):\n",
    "   - The median quantity ordered is 1, as shown by the single line at the bottom of the plot.\n",
    "   - The box is compressed into this line, indicating that at least 75% of orders are for a single item.\n",
    "   - There are multiple outliers, with some orders reaching quantities of 2, 3, 4, 5, 6, 7, and even 9 items.\n",
    "   - The distribution is extremely right-skewed, with most orders being for single items but occasional bulk orders.\n",
    "\n",
    "Observations and meanings:\n",
    "\n",
    "1. Product Range: The company likely sells a wide range of products, from inexpensive accessories to high-end electronics or appliances.\n",
    "\n",
    "2. Pricing Strategy: The presence of many low-priced items with a few very high-priced outliers suggests a strategy of offering a mix of affordable products and premium options.\n",
    "\n",
    "3. Buying Behavior: Customers typically purchase one item at a time, which could indicate:\n",
    "   - Products are often bought individually rather than in sets.\n",
    "   - Each product might fulfill a specific need, not requiring multiple purchases.\n",
    "   - High-value items are less likely to be bought in bulk.\n",
    "\n",
    "4. Inventory Management: The business should be prepared to stock more of the lower-priced items and fewer of the expensive ones.\n",
    "\n",
    "5. Sales Analysis: When analyzing sales data, it's crucial to consider these outliers, as high-priced items sold in small quantities might significantly impact total revenue.\n",
    "\n",
    "6. Marketing Implications: The company might want to focus on upselling or cross-selling strategies to increase the quantity ordered, especially for lower-priced items.\n",
    "\n",
    "7. Customer Segmentation: There might be different customer segments - those who buy single, low-priced items, and those who occasionally make large or expensive purchases.\n",
    "\n",
    "8. Data Quality: It's worth verifying if the extreme outliers in both price and quantity are accurate or if they represent data entry errors.\n",
    "\n",
    "These insights can be valuable for pricing strategies, inventory management, marketing campaigns, and overall business strategy. The presence of outliers in both price and quantity suggests a diverse product range and customer base, which the company can leverage for targeted strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact and Github Repository\n",
    "st.subheader(\"Need Help or Collaboration?\")\n",
    "st.markdown(\"\"\"\n",
    "For collaboration or support, please contact Team Fiji.\n",
    "\"\"\")\n",
    "if st.button(\"Visit Our GitHub Repository\"):\n",
    "    st.markdown(\"[GitHub Repository](https://github.com/your-repo-link)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import random\n",
    "\n",
    "# Set custom theme for dark royal blue\n",
    "st.set_page_config(page_title=\"2019 BI Solution for Sales & Efficiency\", page_icon=\"üìä\", layout=\"wide\")\n",
    "\n",
    "# Apply dark royal blue theme\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        .main {\n",
    "            background-color: #1E3A8A;\n",
    "            color: white;\n",
    "        }\n",
    "        footer {visibility: hidden;}\n",
    "        .css-18e3th9 {\n",
    "            background-color: #1E3A8A;\n",
    "            color: white;\n",
    "        }\n",
    "    </style>\n",
    "    \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "# Sidebar Navigation\n",
    "st.sidebar.title(\"2019 BI Solution\")\n",
    "st.sidebar.subheader(\"Navigation\")\n",
    "options = st.sidebar.radio(\"Go to\", [\"Sales Overview\", \"Product Analysis\", \"City Insights\", \"Seasonality Trends\"])\n",
    "\n",
    "# Random Sales Fact\n",
    "random_facts = [\n",
    "    \"Did you know? Our highest sales volume occurred in May 2019.\",\n",
    "    \"Fun fact: Products priced above $99.99 generate 40% more revenue.\",\n",
    "    \"Surprising stat: The city with the highest number of deliveries is New York!\",\n",
    "    \"Tip: Sales volume peaks during holidays, plan your inventory accordingly.\"\n",
    "]\n",
    "st.sidebar.markdown(f\"üí° *Random Fact:* {random.choice(random_facts)}\")\n",
    "\n",
    "# Load the dataset (df_2019.csv)\n",
    "@st.cache\n",
    "def load_data():\n",
    "    data = pd.read_csv('df_2019.csv')  # Replace with the actual path if needed\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "# Pages in the app based on the client's BI needs\n",
    "if options == \"Sales Overview\":\n",
    "    st.title(\"üìä Sales Overview: 2019\")\n",
    "    \n",
    "    # Summarize total sales\n",
    "    total_sales = data['Sales Volume'].sum()\n",
    "    high_level_sales = data[data['Unit Price'] > 99.99]['Sales Volume'].sum()\n",
    "    \n",
    "    st.metric(label=\"Total Sales Volume (2019)\", value=total_sales)\n",
    "    st.metric(label=\"High-Level Product Sales (>$99.99)\", value=high_level_sales)\n",
    "    \n",
    "    # Show percentage of high-level product sales\n",
    "    progress = int((high_level_sales / total_sales) * 100)\n",
    "    st.progress(progress)  # Show progress of high-level sales\n",
    "    \n",
    "    # Interactive sales volume chart by product\n",
    "    fig = px.bar(data, x=\"Product\", y=\"Sales Volume\", color=\"Product\", title=\"Product Sales Volume (2019)\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "elif options == \"Product Analysis\":\n",
    "    st.title(\"üîç Product Analysis\")\n",
    "    \n",
    "    # Analyze product performance based on unit price and sales volume\n",
    "    st.write(\"Evaluate product performance by pricing and sales volume.\")\n",
    "    fig = px.scatter(data, x=\"Unit Price\", y=\"Sales Volume\", color=\"Product\", size=\"Unit Price\", hover_name=\"Product\",\n",
    "                     title=\"Product Pricing vs Sales Volume\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "elif options == \"City Insights\":\n",
    "    st.title(\"üåÜ City Insights\")\n",
    "    \n",
    "    # Group sales by city\n",
    "    city_sales = data.groupby(\"City\")['Sales Volume'].sum().reset_index()\n",
    "    \n",
    "    # City-wise sales distribution using a pie chart\n",
    "    fig = px.pie(city_sales, names=\"City\", values=\"Sales Volume\", title=\"City-wise Sales Distribution (2019)\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    st.success(f\"The city with the highest deliveries is *{city_sales.loc[city_sales['Sales Volume'].idxmax(), 'City']}*.\")\n",
    "\n",
    "elif options == \"Seasonality Trends\":\n",
    "    st.title(\"üìÖ Seasonality Trends\")\n",
    "    \n",
    "    st.write(\"Analyze how sales change across months to identify seasonal trends.\")\n",
    "    \n",
    "    # Assuming the data has a 'Month' column with values like 'Jan', 'Feb', etc.\n",
    "    monthly_sales = data.groupby('Month')['Sales Volume'].sum().reset_index()\n",
    "    \n",
    "    # Display a line chart for monthly sales trends\n",
    "    fig = px.line(monthly_sales, x=\"Month\", y=\"Sales Volume\", title=\"Monthly Sales Volume in 2019\")\n",
    "    st.plotly_chart(fig, use_container_width=True)\n",
    "    \n",
    "    st.info(\"Note: Seasonal insights help improve stock and marketing strategies.\")\n",
    "\n",
    "# Interactive feedback with emojis\n",
    "st.sidebar.markdown(\"### How did you find this dashboard? üòä\")\n",
    "st.sidebar.button(\"üëç Love it!\")\n",
    "st.sidebar.button(\"üëé Needs more features\")\n",
    "\n",
    "# Footer (Optional)\n",
    "st.markdown(\"<footer>Powered by getINNOtized | ¬© 2024</footer>\", unsafe_allow_html=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_caps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
